# ğŸ” GalLens â€” Visionâ€“Language System for Poultry Disease Diagnosis & Explanation  

GalLens is a **Visionâ€“Language-based system** for **chicken disease diagnosis and explanation**, designed to support **non-expert poultry farmers**.

Unlike standard CNN classifiers that only output a label, GalLens:
- **Understands images** (Vision)
- **Understands language** (LLM)
- **Reasons with medical knowledge via RAG**
- Provides **human-readable explanations + treatment guidance** grounded in real veterinary documents.

This repository accompanies the undergraduate thesis:

> **Visionâ€“Language Based Poultry Disease Diagnosis and Explanation System**  
> University of Science and Technology of Hanoi (USTH)

---

## ğŸ¯ Core Goals

GalLens answers two key questions:

1. **What disease does this chicken have?** â†’ *Visual diagnosis*  
2. **Why and what should I do?** â†’ *Grounded explanation + treatment via RAG*

---

## ğŸ” Full Workflow (Phase 3)

![Pipeline](Figure/Phase3.png)

### High-level pipeline

1. **User input:** Image + Question  
2. **Router decides mode:**
   - If **diagnosis** â†’ use fine-tuned VLM  
   - If **treatment / medical question** â†’ activate RAG + VLM  
3. **If RAG is used:**
   - Retrieve relevant veterinary documents  
   - Inject knowledge into the model prompt  
4. **Final output:**
   - Disease label  
   - Natural-language explanation grounded in evidence  

---

## ğŸ§  Two Inference Modes

### ğŸ”¹ Visual Diagnosis Mode  
**Input:**  
- Chicken image  
- Question: *â€œWhat disease is this?â€*

**Output:**  
- Predicted disease  
- Visual symptom explanation  

### ğŸ”¹ Medical Consultation Mode  
**Input:**  
- Text question like *â€œHow to treat Newcastle disease?â€*

**Output:**  
- Retrieved medical evidence  
- Grounded, safe explanation  

---

## ğŸ“‚ Repository Structure (recommended)

Vision-Language-Model/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw_images/
â”‚ â”œâ”€â”€ vqa_train.jsonl
â”‚ â””â”€â”€ vqa_test.jsonl
â”‚
â”œâ”€â”€ finetune/
â”‚ â”œâ”€â”€ train_lora_qwen2_vl.py
â”‚ â””â”€â”€ lora_config.yaml
â”‚
â”œâ”€â”€ rag/
â”‚ â”œâ”€â”€ build_kb.py
â”‚ â”œâ”€â”€ embed_qwen3.py
â”‚ â””â”€â”€ retrieve.py
â”‚
â”œâ”€â”€ inference/
â”‚ â”œâ”€â”€ vlm_infer.py
â”‚ â””â”€â”€ rag_infer.py
â”‚
â”œâ”€â”€ Figure/
â”‚ â”œâ”€â”€ Phase3.png
â”‚ â”œâ”€â”€ cm_base_model.png
â”‚ â””â”€â”€ cm_expert_model.png
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## ğŸ§  Model Fine-Tuning

### Base model  
- **Qwen2-VL-7B Instruct**

### Fine-tuning method  
- **LoRA (Low-Rank Adaptation)**

### Tested configurations  
| Model | Setting |
|---|---|
| **Model A (Base)** | Zero-shot, no fine-tuning |
| **Model B (10%)** | LoRA full-linear, 10% data |
| **Model C (40%)** | LoRA full-linear, 40% data |
| **Model D** | LoRA only on Attention layers |
| **Model Final â€” GalLens-Integrated** | **LoRA on all linear layers (Champion)** |

---

## ğŸ§© Retrieval-Augmented Generation (RAG)

### Knowledge sources
- Veterinary manuals  
- Medical guidelines  
- Research papers  
- PDF documents  
- Trusted agriculture websites  

### Embedding model
- **Qwen3-Embedding-0.6B**

### Vector database
- **FAISS / Chroma**

---

## ğŸ“¦ Core Packages

Your project relies on:

torch
transformers
peft
accelerate
bitsandbytes
faiss-cpu
chromadb
sentence-transformers
pandas
numpy
tqdm
pillow
fastapi
uvicorn


---

## ğŸš€ How to Run (STEP-BY-STEP)

### **1) Create environment**

```bash
conda create -n gallens python=3.10
conda activate gallens

### **2) Install dependencies
pip install -r requirements.txt


(If you donâ€™t have requirements.txt yet, create one with these lines:)

torch
transformers
peft
accelerate
bitsandbytes
faiss-cpu
chromadb
sentence-transformers
pandas
numpy
tqdm
pillow
fastapi
uvicorn


### **ğŸ§  3) Fine-tune the VLM (optional)
python finetune/train_lora_qwen2_vl.py \
  --train_data data/vqa_train.jsonl \
  --model_path Qwen/Qwen2-VL-7B-Instruct \
  --output_dir models/gallens_expert


This will save:

models/gallens_expert/

### **ğŸ” 4) Build RAG Knowledge Base
python rag/build_kb.py \
  --docs_path rag/docs/ \
  --embed_model Qwen/Qwen3-Embedding-0.6B \
  --vector_store rag/faiss_index

### **ğŸ§ª 5) Run inference
Diagnosis only
python inference/vlm_infer.py \
  --image data/sample.jpg \
  --question "What disease is this?"

Diagnosis + RAG
python inference/rag_infer.py \
  --image data/sample.jpg \
  --question "How to treat this disease?"

### **ğŸŒ 6) Run Web API (optional)
uvicorn app:app --reload


Then open:

http://127.0.0.1:8000/docs

